{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron\n",
    "\n",
    "In this notebook, we briefly introduce the multilayer perceptron model, then apply it on the CVDs dataset.\n",
    "\n",
    "---\n",
    "\n",
    "## Introduce \n",
    "\n",
    "A [multilayer perceptron](https://en.wikipedia.org/wiki/Multilayer_perceptron) (MLP) is a class of feedforward artificial neural network (ANN). An MLP consists of at least three layers of nodes: an input layer, a hidden layer and an output layer. Except for the input nodes, each node is a neuron that uses a nonlinear activation function. MLP utilizes a supervised learning technique called backpropagation for training. Its multiple layers and non-linear activation distinguish MLP from a linear perceptron. It can distinguish data that is not linearly separable.\n",
    "\n",
    "---\n",
    "\n",
    "## Algorithm\n",
    "\n",
    "A multilayer neural network is multilayer of perceptrons. It consists an input layer, several hidden layers, output layer, fully connected weights and non-linear activation function. The architecture of MLP is shown in the following image.\n",
    "\n",
    "<img src=\"multilayerPerceptron.jpg\" alt=\"Drawing\" style=\"width: 450px;\"/>\n",
    "\n",
    "For our activation function, we will use the sigmoid function:\n",
    "\n",
    "* Sigmoid Function\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1+e^{-z}}.\n",
    "$$\n",
    "\n",
    "For our cost function, we will use the Mean Sqaure Error cost:\n",
    "$$\n",
    "C(W, b) = \\frac{1}{2}\\sum_{k=1}^{2}(\\hat{y}^{(i)}_k - y^{(i)}_k)^2.\n",
    "$$\n",
    "\n",
    "### Feedforward Phase\n",
    "\n",
    "For $\\ell = 1, \\dots, L$, each layer $\\ell$ in our network will have two phases, the preactivation phase $$\\mathbf{z}^{\\ell} = W^{\\ell}\\mathbf{a}^{\\ell-1} + \\mathbf{b}^{\\ell},$$ and postactivation phase $$\\mathbf{a}^{\\ell} = \\sigma(\\mathbf{z}^{\\ell}).$$ The preactivation phase consists of a weighted linear combination of postactivation values in the previous layer. The postactivation values consists of passing the preactivation value through an activation function elementwise. Note $\\mathbf{a}^0 = \\mathbf{x}^{(i)}$, where $\\mathbf{x}^{(i)}$ is the current input data into our network. \n",
    "\n",
    "### Backpropogation Phase with Stochastic Gradient Descent \n",
    "The backpropogation phase with stochastic gradient descetn is shown as below:\n",
    "\n",
    "1. For each $i = 1, \\dots, N$.\n",
    "2. Feedforward $\\mathbf{x}^{(i)}$ into the network. \n",
    "3. Compute $\\delta^{L} = \\nabla_aC\\otimes \\sigma'(\\mathbf{z}^{L})$.\n",
    "4. For $\\ell = L-1, \\dots, 1$, compute $\\delta^{\\ell} = \\big ( (\\mathbf{w}^{\\ell + 1})^{T} \\delta^{\\ell + 1} \\Big )\\otimes \\sigma'(\\mathbf{z}^{\\ell})$.\n",
    "5. For $\\ell = L, L-1, \\dots, 1$, \n",
    "\n",
    "$$\n",
    "w^{\\ell} \\leftarrow w^{\\ell} - \\alpha \\delta^{\\ell}(\\mathbf{a}^{\\ell-1})^{T}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b^{\\ell} \\leftarrow b^{\\ell} - \\alpha \\delta^{\\ell}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Set theme for plotting\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define our sigmoid activation function, its derivative, and the mean squared error for a single instance of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def d_sigmoid(z):\n",
    "    return sigmoid(z)*(1.0 - sigmoid(z))\n",
    "\n",
    "def mse(a, y):\n",
    "    return .5*sum((a[i] - y[i])**2 for i in range(len(y)))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we write a custom function to initialize the weight matrices and bias column vectors for a dense neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(layers):\n",
    "    # The following Python lists will contain numpy matrices\n",
    "    # connected the layers in the neural network \n",
    "    W = [[0.0]]\n",
    "    B = [[0.0]]\n",
    "    for i in range(1, len(layers)):\n",
    "        # The scalling factor is something I found in a research paper :)\n",
    "        w_temp = np.random.randn(layers[i], layers[i-1])*np.sqrt(2/layers[i-1])\n",
    "        b_temp = np.random.randn(layers[i], 1)*np.sqrt(2/layers[i-1])\n",
    "    \n",
    "        W.append(w_temp)\n",
    "        B.append(b_temp)\n",
    "    return W, B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the feedforward phase funciton and the overall MSE cost funciton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(W, B, xi, predict_vector = False):\n",
    "    Z = [[0.0]]\n",
    "    A = [xi]\n",
    "    L = len(W) - 1\n",
    "    for i in range(1, L + 1):\n",
    "        z = W[i] @ A[i-1] + B[i]\n",
    "        Z.append(z)\n",
    "        \n",
    "        a = sigmoid(z)\n",
    "        A.append(a)\n",
    "        \n",
    "    if predict_vector == False:\n",
    "        return Z, A\n",
    "    else:\n",
    "        return A[-1]\n",
    "\n",
    "def MSE(W, B, X, y):\n",
    "    cost = 0.0\n",
    "    m = 0\n",
    "    for xi, yi in zip(X, y):\n",
    "        xi = xi.reshape(-1,1)\n",
    "        a = forward_pass(W, B, xi, predict_vector = True)\n",
    "        cost += mse(a, yi)\n",
    "        m+=1\n",
    "    return cost/m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to define a custom Python ```DenseNetwork``` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNetwork(object):\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        self.W, self.B = initialize_weights(layers = self.layers)\n",
    "\n",
    "    def train(self, X_train, y_train, alpha = 0.046, epochs = 10):\n",
    "        # Print the initial mean squared error\n",
    "        self.errors_ = [MSE(self.W, self.B, X_train, y_train)]\n",
    "        print(f\"Starting Cost = {self.errors_[0]}\")\n",
    "\n",
    "        # Find your sample size\n",
    "        sample_size = len(X_train)\n",
    "\n",
    "        # Find the number of non-input layers.\n",
    "        L = len(self.layers) - 1\n",
    "\n",
    "        # For each epoch perform stochastic gradient descent. \n",
    "        for k in range(epochs):\n",
    "            # Loop over each (xi, yi) training pair of data.\n",
    "            for xi, yi in zip(X_train, y_train):\n",
    "                # Use the forward pass function defined before\n",
    "                # and find the preactivation and postactivation values.\n",
    "                xi = xi.reshape(-1,1)\n",
    "                Z, A = forward_pass(self.W, self.B, xi)\n",
    "\n",
    "                # Store the errors in a dictionary for clear interpretation\n",
    "                # of computation of these values.\n",
    "                deltas = dict()\n",
    "\n",
    "                # Compute the output error \n",
    "                output_error = (A[L] - yi)*d_sigmoid(Z[L])\n",
    "                deltas[L] = output_error\n",
    "\n",
    "                # Loop from L-1 to 1. Recall the right entry of the range function \n",
    "                # is non-inclusive. \n",
    "                for i in range(L-1, 0, -1):\n",
    "                    # Compute the node errors at each hidden layer\n",
    "                    deltas[i] = (self.W[i+1].T @ deltas[i+1])*d_sigmoid(Z[i])\n",
    "\n",
    "                # Loop over each hidden layer and the output layer to perform gradient \n",
    "                # descent. \n",
    "                for i in range(1, L+1):\n",
    "                    self.W[i] -= alpha*deltas[i] @ A[i-1].T\n",
    "                    self.B[i] -= alpha*deltas[i]\n",
    "\n",
    "            # Show the user the cost over all training examples\n",
    "            self.errors_.append(MSE(self.W, self.B, X_train, y_train))   \n",
    "            print(f\"{k + 1}-Epoch Cost = {self.errors_[-1]}\")\n",
    "    \n",
    "\n",
    "    def predict(self, xi):\n",
    "        depth = len(self.layers)\n",
    "        _, A = forward_pass(self.W, self.B, xi)\n",
    "        return np.argmax(A[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "df = pd.read_csv(\"./Datasets/palmer_penguins.csv\")\n",
    "\n",
    "# Data Preprocessing by onehot encoding\n",
    "# df.species = df.species.replace({'Adelie':0, 'Chinstrap':1, 'Gentoo':2})\n",
    "df.sex = df.sex.replace({'Male': 0, 'Female':1})\n",
    "island = pd.get_dummies(df.island)\n",
    "species = pd.get_dummies(df.species)\n",
    "df = pd.concat([df, island, species], axis = 1)\n",
    "df.drop(['Unnamed: 0','island', 'species'],axis=1,inplace=True)\n",
    "\n",
    "# Standardize the data\n",
    "df.bill_length_mm = preprocessing.scale(df.bill_length_mm)\n",
    "df.bill_depth_mm = preprocessing.scale(df.bill_depth_mm)\n",
    "df.flipper_length_mm = preprocessing.scale(df.flipper_length_mm)\n",
    "df.body_mass_g = preprocessing.scale(df.body_mass_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>Biscoe</th>\n",
       "      <th>Dream</th>\n",
       "      <th>Torgersen</th>\n",
       "      <th>Adelie</th>\n",
       "      <th>Chinstrap</th>\n",
       "      <th>Gentoo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.896042</td>\n",
       "      <td>0.780732</td>\n",
       "      <td>-1.426752</td>\n",
       "      <td>-0.568475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.822788</td>\n",
       "      <td>0.119584</td>\n",
       "      <td>-1.069474</td>\n",
       "      <td>-0.506286</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.676280</td>\n",
       "      <td>0.424729</td>\n",
       "      <td>-0.426373</td>\n",
       "      <td>-1.190361</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.335566</td>\n",
       "      <td>1.085877</td>\n",
       "      <td>-0.569284</td>\n",
       "      <td>-0.941606</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.859415</td>\n",
       "      <td>1.747026</td>\n",
       "      <td>-0.783651</td>\n",
       "      <td>-0.692852</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>0.587352</td>\n",
       "      <td>-1.762145</td>\n",
       "      <td>0.931283</td>\n",
       "      <td>0.892957</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>0.514098</td>\n",
       "      <td>-1.457000</td>\n",
       "      <td>1.002739</td>\n",
       "      <td>0.799674</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1.173384</td>\n",
       "      <td>-0.744994</td>\n",
       "      <td>1.502928</td>\n",
       "      <td>1.919069</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>0.221082</td>\n",
       "      <td>-1.202712</td>\n",
       "      <td>0.788372</td>\n",
       "      <td>1.234995</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>1.081817</td>\n",
       "      <td>-0.541564</td>\n",
       "      <td>0.859828</td>\n",
       "      <td>1.483749</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g  sex  \\\n",
       "0         -0.896042       0.780732          -1.426752    -0.568475    0   \n",
       "1         -0.822788       0.119584          -1.069474    -0.506286    1   \n",
       "2         -0.676280       0.424729          -0.426373    -1.190361    1   \n",
       "3         -1.335566       1.085877          -0.569284    -0.941606    1   \n",
       "4         -0.859415       1.747026          -0.783651    -0.692852    0   \n",
       "..              ...            ...                ...          ...  ...   \n",
       "328        0.587352      -1.762145           0.931283     0.892957    1   \n",
       "329        0.514098      -1.457000           1.002739     0.799674    1   \n",
       "330        1.173384      -0.744994           1.502928     1.919069    0   \n",
       "331        0.221082      -1.202712           0.788372     1.234995    1   \n",
       "332        1.081817      -0.541564           0.859828     1.483749    0   \n",
       "\n",
       "     Biscoe  Dream  Torgersen  Adelie  Chinstrap  Gentoo  \n",
       "0         0      0          1       1          0       0  \n",
       "1         0      0          1       1          0       0  \n",
       "2         0      0          1       1          0       0  \n",
       "3         0      0          1       1          0       0  \n",
       "4         0      0          1       1          0       0  \n",
       "..      ...    ...        ...     ...        ...     ...  \n",
       "328       1      0          0       0          0       1  \n",
       "329       1      0          0       0          0       1  \n",
       "330       1      0          0       0          0       1  \n",
       "331       1      0          0       0          0       1  \n",
       "332       1      0          0       0          0       1  \n",
       "\n",
       "[333 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the data set and preprocess it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the training set and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('sex',axis=1).to_numpy()\n",
    "y = df.sex\n",
    "\n",
    "# Create a training set and a testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we onehot encode the response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode the training labels\n",
    "onehot_y_train = []\n",
    "\n",
    "for y in zip(y_train):\n",
    "    temp_vec = np.zeros((2, 1))\n",
    "    temp_vec[y][0] = 1.0\n",
    "    onehot_y_train.append(temp_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize a ```DenseNetwork``` Class with layers = [8,4,4,2]. Then we examine our MLP class by making a random prediction before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE(net.W, net.B, X_train, onehot_y_train) = 0.2972984115656425 \n",
      "\n",
      "predicted label is: 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "40",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2131\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2140\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 40",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m prediction \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mpredict(X_test[i]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted label is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual label is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39margmax(y_test[i])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    955\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    961\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1068\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1069\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 40"
     ]
    }
   ],
   "source": [
    "# Initialize a network with 15 input nodes, two hidden layers with 4 nodes each \n",
    "# and a output layer with 2 nodes. \n",
    "np.random.seed(1)\n",
    "net = DenseNetwork(layers = [10,4,4,2])\n",
    "\n",
    "# Check the mean squared error before training \n",
    "print(f\"MSE(net.W, net.B, X_train, onehot_y_train) = {MSE(net.W, net.B, X_train, onehot_y_train)} \\n\")\n",
    "\n",
    "# Make a random prediction before training\n",
    "np.random.seed(2)\n",
    "i = np.random.randint(0, len(X_test))\n",
    "prediction = net.predict(X_test[i].reshape(-1,1))\n",
    "print(f\"predicted label is: {prediction}\")\n",
    "print(f\"actual label is: {np.argmax(y_test[i])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the MLP on the training set with epochs = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Cost = 0.2972984115656425\n",
      "1-Epoch Cost = 0.2505870879763959\n",
      "2-Epoch Cost = 0.2455987383057647\n",
      "3-Epoch Cost = 0.24377536297629357\n",
      "4-Epoch Cost = 0.2416219211906654\n",
      "5-Epoch Cost = 0.23890748302771728\n",
      "6-Epoch Cost = 0.2354506069426434\n",
      "7-Epoch Cost = 0.23103368429322677\n",
      "8-Epoch Cost = 0.2254184490205837\n",
      "9-Epoch Cost = 0.21838328334389548\n",
      "10-Epoch Cost = 0.20977988301295916\n"
     ]
    }
   ],
   "source": [
    "# Train your network with stochastic gradient descent!\n",
    "net.train(X_train, onehot_y_train, alpha = 0.046, epochs= 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check the prediction result after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted label is: 1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "40",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2131\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2140\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 40",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m prediction \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mpredict(X_test[i]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted label is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual label is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39margmax(y_test[i])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    955\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    961\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1068\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1069\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 40"
     ]
    }
   ],
   "source": [
    "prediction = net.predict(X_test[i].reshape(-1,1))\n",
    "print(f\"predicted label is: {prediction}\")\n",
    "print(f\"actual label is: {np.argmax(y_test[i])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will visualize the MSE over each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the mean squared error over the training process \n",
    "plt.figure(figsize = (10, 8))\n",
    "epochs = range(len(net.errors_))\n",
    "plt.plot(epochs, net.errors_, marker = \"o\")\n",
    "plt.xticks(epochs)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Mean Squared Error\")\n",
    "plt.title(\"Network MSE During Training\", fontsize = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSE decreases over each epoch. Now we will make prediction on the testing set and show the confusion matrix and classificaiton report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on testing data\n",
    "y_pred = []\n",
    "for xi in X_test:\n",
    "    y_pred.append(net.predict(xi.reshape(-1,1)))\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the confusion matrix \n",
    "print(f\"cf_matrix = {cf_matrix} \\n\")\n",
    "\n",
    "# View the confusion matrix using the seaborn package\n",
    "plt.figure(figsize = (10, 8))\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues', cbar=False)\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check performance of our model with classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MLP model's accuracy is 86%, which is greater than the single neuron perceptron model and less than the logistic regression model.\n",
    "\n",
    "---\n",
    "\n",
    "## Using TensorFlow package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf   # import tensorflow package\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(7, activation='sigmoid'),\n",
    "  tf.keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(10, 8))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy by using TensorFlow package is also about 86%.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "From the result above, we can see that the multilayer perceptron model performs well on the CVDs dataset. Compared with the single neuron perceptron model, the multilayer perceptron model has higher accuracy. The main reason is that the multilayer perceptron model can deal with non-linearly separable data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e3de3013aa64c987b0d0ea220a933b22b0d06ac8866ebafdf417a10062e273"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
